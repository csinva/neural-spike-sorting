{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.models\n",
    "from keras.layers.convolutional import Conv1D, ZeroPadding1D\n",
    "from keras.layers.recurrent import Recurrent, LSTM, GRU\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils import np_utils\n",
    "from math import floor, ceil\n",
    "from sklearn.metrics import accuracy_score\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, test sizes (1, 4447004, 1) (1, 9698, 1)\n"
     ]
    }
   ],
   "source": [
    "def load_and_format_data():\n",
    "    # load data\n",
    "    x_train = np.array([])\n",
    "    y_train = np.array([])\n",
    "    for i in range(1,10):\n",
    "        dataset = 'train/'+str(i)\n",
    "        x_data = pd.read_csv(dataset + '.train.calcium.csv')\n",
    "        y_data = pd.read_csv(dataset + '.train.spikes.csv')    \n",
    "        for key in x_data:\n",
    "            x_train = np.concatenate((x_train,x_data[key].dropna()))\n",
    "            y_train = np.concatenate((y_train,y_data[key].dropna()))\n",
    "    x_test = pd.read_csv('train/10' + '.train.calcium.csv')['9'].dropna()\n",
    "    y_test = pd.read_csv('train/10' + '.train.spikes.csv')['9'].dropna()\n",
    "    num_y = int(np.max(y_train+1))\n",
    "    # binarize labels\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_train) # this lb takes 0 -> [1,0,0,0,0], 1-> [0,1,0,0,0], etc.\n",
    "    y_train = lb.transform(y_train)\n",
    "#     y_test = lb.transform(y_test)\n",
    "    # reshape data\n",
    "    x_train = x_train.reshape((1, len(x_train), 1))\n",
    "    y_train = y_train.reshape((1, len(y_train), y_train.shape[1]))\n",
    "    x_test = x_test.values.reshape((1, len(x_test), 1))\n",
    "#     y_test = y_test.reshape((1, len(y_test), y_test.shape[1]))\n",
    "    return x_train, y_train, x_test, y_test, num_y\n",
    "x_train, y_train, x_test, y_test, num_y = load_and_format_data()\n",
    "print(\"train, test sizes\",x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_features = 10\n",
    "embedding_dims = 10\n",
    "kernel_sizes = [21,13,5] # should be odd\n",
    "pad_sizes = [floor(s/2) for s in kernel_sizes]\n",
    "model = keras.models.Sequential()\n",
    "model.add(ZeroPadding1D(padding=pad_sizes[0], input_shape=(None, 1)))\n",
    "model.add(Conv1D(filters=num_y, kernel_size=kernel_sizes[0], activation=\"linear\"))\n",
    "model.add(ZeroPadding1D(padding=pad_sizes[1], input_shape=(None, 1)))\n",
    "model.add(Conv1D(filters=num_y, kernel_size=kernel_sizes[1], activation=\"linear\"))\n",
    "model.add(ZeroPadding1D(padding=pad_sizes[2], input_shape=(None, 1)))\n",
    "model.add(Conv1D(filters=num_y, kernel_size=kernel_sizes[2], activation=\"softmax\"))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 9s - loss: 0.1171 - acc: 0.2176\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 8s - loss: 0.1150 - acc: 0.9163\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 7s - loss: 0.1130 - acc: 0.9545\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 8s - loss: 0.1104 - acc: 0.9614\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 9s - loss: 0.1076 - acc: 0.9642\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 11s - loss: 0.1045 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 13s - loss: 0.1011 - acc: 0.9672\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 9s - loss: 0.0973 - acc: 0.9681\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 9s - loss: 0.0932 - acc: 0.9688\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 9s - loss: 0.0887 - acc: 0.9693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d765dd8>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "model.fit(x_train, y_train, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def size_of_all_data():\n",
    "    for folder in ['train','test']:\n",
    "        nums = []\n",
    "        if folder=='train':\n",
    "            nums = range(1,11)\n",
    "        else:\n",
    "            nums = range(1,6)\n",
    "        for num in nums:\n",
    "            dataset = folder + '/' + str(num)\n",
    "            print(dataset)\n",
    "            data = pd.read_csv(dataset + '.'+folder+'.calcium.csv')  # todo: concat these, trim trailing zeros\n",
    "            for index in data:\n",
    "                print('\\t',index,len(data[index]))\n",
    "size_of_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------training----------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c25dba4d15df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------training----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred nonzeros\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc\\t\\t\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def visualize(calcium, spikes, spikes2=None):\n",
    "    t = np.arange(len(calcium)) / 100.0\n",
    "    plt.hold(True)\n",
    "    plt.plot(t, calcium, color='#348ABD')\n",
    "    plt.plot(t, spikes / 2.0 - 3.2, color='black',label='gt')\n",
    "    if not spikes2==None:\n",
    "        plt.plot(t, spikes2 / 2.0 - 2, color='g',label='pred')\n",
    "        plt.plot(t, (spikes-spikes2) / 2.0 - 5, color='r',label='diff')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.ylim([-6, 3])\n",
    "    plt.xlim([0,100])\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "print('----------training----------')\n",
    "y_pred = np.argmax(model.predict(x_train)[0,:,:],axis=1)\n",
    "print('pred nonzeros\\t',str(np.sum(y_pred) / y_pred.size))\n",
    "print(\"acc\\t\\t\",accuracy_score(y_pred,np.argmax(y_train[0,:,:],axis=1)))\n",
    "print(\"corr\\t\\t\",np.corrcoef(y_pred,np.argmax(y_train[0,:,:],axis=1))[0,1])\n",
    "\n",
    "print('----------testing----------')\n",
    "y_pred = np.argmax(model.predict(x_test)[0,:,:],axis=1)\n",
    "print('pred nonzeros\\t',str(np.sum(y_pred) / y_pred.size))\n",
    "print(\"acc\\t\\t\",accuracy_score(y_pred,y_test))\n",
    "print(\"corr\\t\\t\",np.corrcoef(y_pred,y_test)[0,1])\n",
    "plt.figure(figsize=(18, 6))\n",
    "visualize(x_test[0,:,0],y_test,y_pred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
